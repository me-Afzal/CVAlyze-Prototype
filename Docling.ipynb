{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e042df2a-900f-4ff5-8661-fff20f2bc1e4",
   "metadata": {},
   "source": [
    "# Testing Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd5927d-1fd5-4717-a1b0-77a1015dbbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 16:56:40,166 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-14 16:56:40,170 - INFO - Going to convert document batch...\n",
      "2025-10-14 16:56:40,171 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-10-14 16:56:40,173 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-14 16:56:42,095 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-14 16:56:43,072 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-14 16:56:43,557 - INFO - Processing document albin.pdf\n",
      "2025-10-14 16:56:47,774 - INFO - Finished converting document albin.pdf in 7.62 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "\n",
      "## Profile Summary\n",
      "\n",
      "A MERN stack developer from Kochi with a strong focus on backend-heavy full-stack development. Skilled in building robust, efficient, and secure server-side applications. Committed to continuous learning and passionate about distributed systems, with a dedication to delivering high-quality solutions.\n",
      "\n",
      "## Technical Skills\n",
      "\n",
      "Programming Languages:\n",
      "\n",
      "JavaScript, TypeScript\n",
      "\n",
      "Back End Development: Node.js, Express.js, Next.js, GraphQL, RESTful APIs, Socket.io, MVC Architecture, SOLID Principles, Clean Architecture, Modular Monolithic\n",
      "\n",
      "Front End Development:\n",
      "\n",
      "React.js, Redux, Next.js, TanStack Query\n",
      "\n",
      "Database:\n",
      "\n",
      "PostgreSQL, MongoDB\n",
      "\n",
      "Tools:\n",
      "\n",
      "Docker, CI/CD, Postman, Git, Figma\n",
      "\n",
      "Familiar with: JWT, Tailwind CSS, Bootstrap, Stripe, Razorpay, PayPal, Cloudinary, WebHooks, AWS, GDC, Nginx, Firebase, OAuth2.0, Clerk Authentication, Nodemailer, Multer, Data Structures and Algorithms\n",
      "\n",
      "## Main Projects\n",
      "\n",
      "## Zyra Moments, Event Management and Hosting Platform\n",
      "\n",
      "Live Link | GitHub\n",
      "\n",
      "Zyra Moments is a comprehensive platform connecting users with vendors for seamless event planning and hosting. It features ticketing, QR-based attendance tracking, and real-time chat for enhanced user engagement. The system is built with a focus on scalability, security, and cross-platform compatibility.\n",
      "\n",
      "- Comprehensive Features: Enabled event browsing, ticketing, QR code generation/scanning, and real-time chat with Socket.IO.\n",
      "- Robust Backend: Developed using Express.js and MongoDB, with JWT for authentication and Redis for caching.\n",
      "- Clean Architecture: Applied SOLID principles and Clean Architecture for maintainability and scalability.\n",
      "- Mobile Integration: Collaborated on a mobile app for consistent cross-platform functionality (in development).\n",
      "- DevOps: Implemented CI/CD pipeline and AWS EC2 hosting with Winston logger for efficient deployment.\n",
      "\n",
      "Technologies Used: Express.js, TypeScript, Node.js, MongoDB, JWT, Socket.IO, Redis, React, React Query, Redux, AWS EC2, S3, Cloudfront, Git, GitHub, Postman\n",
      "\n",
      "## Cell Sphere, E-commerce Website\n",
      "\n",
      "Live Link | GitHub\n",
      "\n",
      "Cell Sphere is a specialized e-commerce platform for mobile phones with advanced filtering and secure checkout.\n",
      "\n",
      "- Key Features: Implemented offers, coupons, wishlist, wallet, referral system, and order tracking.\n",
      "- Secure Payments: Integrated Razorpay and PayPal with OTP confirmation via Nodemailer.\n",
      "- MVC Architecture: Built with Node.js, Express.js, and MongoDB for scalability and maintainability.\n",
      "- Authentication: Used JWT and Google OAuth for secure user access.\n",
      "- Deployment: Leveraged AWS EC2, Nginx, Certbot, and PM2 for a high-performing, secure, and scalable platform.\n",
      "\n",
      "Technologies Used: Node.js, Express.js, MongoDB, JWT, React.js, Redux, React Query, Vite, AWS, Nginx, Certbot, PM2, Razorpay, PayPal, Git, GitHub\n",
      "\n",
      "## Albin Aji\n",
      "\n",
      "## MERN Stack Developer\n",
      "\n",
      "Location : Kerala,India |+91 95395 47616 | albinpariyarathu@gmail.com | LinkedIn | GitHub\n",
      "\n",
      "## Mini Projects\n",
      "\n",
      "## SocialiteX, Social Media Platform\n",
      "\n",
      "Live Link | GitHub\n",
      "\n",
      "A modern social media platform for connecting, sharing posts, and engaging in real-time with a responsive UI.\n",
      "\n",
      "- User Engagement &amp; Authentication: Enabled post creation, comments, and likes with real-time updates, plus secure login using Clerk.\n",
      "- Data &amp; UI: Scalable database operations with Prisma and PostgreSQL, and accessible UI with Next.js, Radix UI, and Tailwind CSS.\n",
      "\n",
      "Technologies Used: Next.js, TypeScript, Prisma, PostgreSQL, Clerk, Radix UI, Tailwind CSS, UploadThing, Git, GitHub\n",
      "\n",
      "## Invento Sync, Inventory Management System\n",
      "\n",
      "Live Link | GitHub\n",
      "\n",
      "A web app for streamlined inventory, sales, and customer management with a responsive UI and robust reporting.\n",
      "\n",
      "- User Authentication &amp; CRUD: Secure login with JWT and bcrypt, and efficient inventory management using MongoDB and Mongoose.\n",
      "- Reporting &amp; UI: Sales and ledger reports with Excel, PDF, and email exports, built with React, TypeScript, Ant Design, and Tailwind CSS.\n",
      "\n",
      "Technologies Used: React, TypeScript, Express, MongoDB, Mongoose, JWT, bcrypt, Ant Design, Tailwind CSS, ExcelJS, PDFKit, Nodemailer, Axios, Git, GitHub\n",
      "\n",
      "## Snap Stocker, Image Stock Platform\n",
      "\n",
      "Live Link | GitHub\n",
      "\n",
      "A MERN-stack web app for managing a stock image library with secure authentication and intuitive drag-and-drop functionality.\n",
      "\n",
      "- Authentication &amp; Image Management: Secure user registration and login with JWT, plus bulk image upload, edit, and delete using Express.js and MongoDB.\n",
      "- Drag-and-Drop UI: Built with React.js, Tailwind CSS, and dnd-kit for responsive, user-friendly image reordering.\n",
      "\n",
      "Technologies Used: React.js, Express.js, Node.js, MongoDB, JWT, dnd-kit, Tailwind CSS, Git, GitHub\n",
      "\n",
      "## Product\n",
      "\n",
      "## Go Keral, No-Commission Vehicle Booking System\n",
      "\n",
      "Live Link\n",
      "\n",
      "A platform for direct vehicle bookings, empowering rural tourism with no third-party commissions.\n",
      "\n",
      "- User-Friendly &amp; Tracking: No-login interface with React.js and TypeScript, plus real-time tracking via Google Maps API.\n",
      "- Scalable Backend: Built with NestJS and MongoDB for efficient, modular performance.\n",
      "\n",
      "Technologies Used: React.js, TypeScript, NestJS, MongoDB, Google Maps API, Git, GitHub\n",
      "\n",
      "## Education\n",
      "\n",
      "| MERN Full Stack Development Brototype, Calicut                          | 2024 - Present Certificate   |\n",
      "|-------------------------------------------------------------------------|------------------------------|\n",
      "| BSc in Computer Science                                                 | 2021 - 2024                  |\n",
      "| St. Thomas College - MG University Higher Secondary in Computer Science | 2019 - 2021                  |\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = \"og_cv/albin.pdf\" \n",
    "converter = DocumentConverter()\n",
    "doc = converter.convert(source).document\n",
    "\n",
    "print(doc.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c79066c-1ffe-4592-9313-253eba392c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afzal\\Jupyter Workspace\\Week 52\\ETL project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-14 16:47:33,880 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-14 16:47:37,348 - INFO - Going to convert document batch...\n",
      "2025-10-14 16:47:37,349 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-10-14 16:47:37,367 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-14 16:47:37,372 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-10-14 16:47:37,398 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-14 16:47:37,411 - INFO - Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-10-14 16:47:37,986 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-14 16:47:39,992 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-14 16:47:41,407 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-14 16:47:42,282 - INFO - Processing document afzal.pdf\n",
      "2025-10-14 16:47:48,773 - INFO - Finished converting document afzal.pdf in 14.89 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links: https://article-researcher-app-cbngx5mmmxxdtjzfewngtn.streamlit.app/, https://github.com/me-Afzal/, https://github.com/me-Afzal/Article-Researcher-app, https://github.com/me-Afzal/Bank_Analysis, https://github.com/me-Afzal/Data-ETL-Pipeline, https://github.com/me-Afzal/Fake-News-Detection, https://github.com/me-Afzal/Harry_Potter_Cloak_Invisibility, https://github.com/me-Afzal/Hybrid-movie-recommendation-app, https://github.com/me-Afzal/IPL_win_probability_predictor, https://github.com/me-Afzal/Image-Enhancer-Pro, https://github.com/me-Afzal/Medical-cost-predictor, https://github.com/me-Afzal/NoteKeeper, https://github.com/me-Afzal/True-Buddy-Chatbot, https://hybrid-movie-recommend-app.streamlit.app/, https://ipl-win-probability-predictor-tool.streamlit.app/, https://linkedin.com/in/afzal-a-0b1962325, https://medical-cost-predictor-web.streamlit.app/, https://true-buddy-chatbot.streamlit.app/\n",
      "\n",
      "<!-- image --> ## Professional Summary Data Scientist and AI/ML Engineer with hands-on experience in statistical analysis, machine learning, deep learning, and big data engineering. Skilled in developing end-to-end data-driven solutions using tools and frameworks such as Python, TensorFlow, scikit-learn, FastAPI, and Apache Spark. Proficient in NLP, Computer Vision, and Transformer-based Large Language Models (LLMs) for advanced AI applications, including Generative AI (VAE, GAN). Experienced with SQL, BI tools, and cloud computing platforms for scalable data solutions. Strong understanding of microservices architecture, Hadoop, and Kafka for distributed processing and real-time analytics. Holds a Bachelor's degree in Commerce (Accounts and Data Science, 2021-2024) and specialized in Data Science through Brototype, combining technical depth with domain knowledge to deliver innovative, business-driven outcomes. ## Technical Skills Programming &amp; Libraries: Python, TensorFlow, PyTorch, scikit-learn, Pandas, NumPy, OpenCV, Transformers (LLMs), NLP, Computer Vision, Generative AI (VAE, GAN) Big Data &amp; Cloud: Apache Spark, Hadoop, Kafka, AWS, GCP, Azure Database &amp; Querying: SQL, PostgreSQL, MySQL, Query Optimization, Database Design Web &amp; Deployment: FastAPI, Microservices, Docker, Kubernetes, REST APIs, JWT Authentication Visualization &amp; BI Tools: Matplotlib, Seaborn, Power BI, Tableau, Data Storytelling Software Practices: System Design, Data Structures and Algorithms ## Professional Projects ## CVAlyze - AI-Powered ETL + CV Analysis Platform (Ongoing Development) An intelligent ETL pipeline currently in development that transforms unstructured CV data into structured formats using a hybrid Regex + RAG (Retrieval-Augmented Generation) approach. - -Designed an AI-driven resume parsing system integrating Gemini API and LangChain RAG . - -Implemented modular data extraction and preprocessing pipeline for name, contact, skills, and experience. - -Optimized performance for large-scale document processing through asynchronous execution. - -Project is ongoing and actively under development to enhance accuracy and scalability. ## Image Enhancer Pro - ESRGAN Image Super-Resolution API A high-quality image enhancement API providing 4x super-resolution using Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN) . - -Built using FastAPI and PyTorch for scalable inference and real-time enhancement. - -Integrated ESRGAN pretrained weights for fine-grained detail recovery and denoising. - -Implemented optimized I/O pipeline for batch image processing. ## Bank Analytics Dashboard A comprehensive analytics dashboard offering insights into customer behavior, deposits, and loan performance. - -Developed interactive visualizations using Power BI and Python-based analytics. - -Applied machine learning models for customer segmentation and risk prediction. - -Enabled real-time KPI tracking and automated report generation. ## Article Research Tool (RAG App) A Retrieval-Augmented Generation (RAG) application for intelligent article summarization and information extraction. - -Integrated LangChain with vector-based retrieval for contextual document search. - -Built semantic search using OpenAI embeddings and FAISS indexing. - -Deployed on Streamlit with modern UI for research-oriented workflows. ## True Buddy Chatbot - Emotional Support AI An intelligent conversational AI providing emotional support using transformer-based models . - -Implemented contextual memory for continuous and empathetic dialogue generation. - -Leveraged LLMs via API for emotional tone detection and adaptive responses. /envelope <!-- image --> Data Scientist afzalkottukkal23@gmail.com /linkedin LinkedIn /github GitHub GitHub GitHub Live Demo GitHub Live Demo GitHub - -Deployed as a Streamlit web app with minimal UI for mental health engagement. ## Medical Insurance Cost Predictor A regression-based ML model predicting medical insurance costs with automated report generation. - -Implemented data preprocessing and regression modeling using scikit-learn . - -Integrated dynamic report creation in PDF format for user predictions. - -Deployed end-to-end ML pipeline with interactive web interface via Streamlit. ## NoteKeeper - FastAPI Microservices Application A microservices-based note-taking platform with JWT-based authentication and modular architecture. - -Developed a FastAPI gateway managing authentication and service routing. - -Implemented user and note microservices communicating through internal APIs. - -Integrated JWT middleware ensuring secure and stateless authentication. ## IPL Win Probability Predictor An AI-powered application predicting live IPL match win probabilities using real-time ML inference. - -Trained machine learning models using past IPL datasets and live match updates. - -Developed interactive dashboard with glassmorphism design using Streamlit. - -Optimized prediction latency for real-time user interaction. ## Additional Projects ## Movie Recommender Pro (Hybrid) An advanced recommendation system combining collaborative filtering and content-based filtering for personalized movie suggestions. - -Implemented hybrid recommendation using cosine similarity and user-item interaction matrices. - -Built with Streamlit for interactive user experience and real-time recommendations. - -Integrated scalable model serving pipeline for fast query response. ## Fake News Detector Live Demo GitHub GitHub Live Demo GitHub Live Demo GitHub GitHub An AI-powered web application that detects fake news using Natural Language Processing (NLP) and Machine Learning . - -Trained and evaluated ML models using TF-IDF , Logistic Regression , and Random Forest . - -Built explainable prediction pipeline for transparency in classification. - -Deployed interactive inference interface using Streamlit. ## Harry Potter Invisibility Cloak - Computer Vision App A real-time computer vision project that creates an invisibility effect using OpenCV and HSV color masking. - -Implemented background subtraction and color segmentation for dynamic masking. - -Integrated face detection using LBP Cascade Classifier for enhanced user interaction. - -Created AR-style invisibility illusion with optimized frame processing. ## Data ETL Pipeline - Warehouse Analytics Platform A comprehensive data pipeline for automating warehouse shipment analytics using ## Google Cloud Platform (GCP) services. - -Designed an ETL pipeline for CSV ingestion, cleaning, and transformation. - -Integrated with BigQuery and Cloud Storage for real-time analytics. - -Enabled business intelligence insights through automated data visualization dashboards. ## Education &amp; Training | Brototype - Data Science and AI/ML Program Comprehensive 1-year Data Science specialization program focused on . | Aug. 2024 - Present Remote / Kochi, Kerala | |--------------------------------------------------------------------------------------------------------------------|----------------------------------------------| | Machine Learning , Deep Learning , MLOps , and Cloud Deployment | | | St. John's College, Anchal (University of Kerala) | Aug. 2021 - Apr. 2024 | | Bachelor of Commerce in Accounts and Data Science . | Kollam, Kerala | | CPHSS Kadakkal Higher Secondary Education in Commerce with Computer Applications . | Jun. 2019 - May. 2021 Kollam, Kerala | GitHub GitHub ## Key Achievements &amp; Certifications - Developed and deployed multiple AI-powered applications leveraging FastAPI , LangChain , and LLMs for intelligent automation and RAG-based systems. - Implemented end-to-end ETL pipelines using Apache Airflow on AWS and GCP Cloud Run, BigQuery, Cloud SQL, and Cloud Storage . - Built and fine-tuned machine learning and deep learning models for real-world use cases in prediction, computer vision, and generative AI. - Deployed scalable microservice architectures on Google Cloud Kubernetes Engine (GKE) and achieved high reliability across services. - Integrated MLOps practices including CI/CD pipelines for model deployment and monitoring in production. - Hands-on expertise in Data Analytics, Python, SQL, and BI tools for actionable insights and data storytelling. - Earned certifications in Data Science , Machine Learning , and Cloud Computing through Brototype and self-driven projects.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz\n",
    "from docling.document_converter import DocumentConverter\n",
    "converter = DocumentConverter()\n",
    "\n",
    "def extract_clean_text(file_path):\n",
    "    \n",
    "    all_links = set()\n",
    "    top_links = []\n",
    "\n",
    "    # Extract hyperlinks from PDF\n",
    "    if str(file_path).lower().endswith(\".pdf\"):\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                for link in page.get_links():\n",
    "                    uri = link.get(\"uri\")\n",
    "                    if uri and uri.startswith(\"http\"):\n",
    "                        all_links.add(uri.strip())\n",
    "\n",
    "    # Extract text using Docling\n",
    "    doc = converter.convert(file_path).document\n",
    "    full_text = doc.export_to_markdown()\n",
    "\n",
    "    # Extract plain-text URLs \n",
    "    url_pattern = re.compile(\n",
    "        r'(https?://[^\\s]+|www\\.[^\\s]+|\\b[\\w-]+\\.(?:vercel|netlify|github|streamlit|huggingface|render|heroku|io|app|ai|com|org)\\b[^\\s]*)',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    for u in url_pattern.findall(full_text):\n",
    "        clean_url = u.strip(\").,;:!?\")\n",
    "        all_links.add(clean_url)\n",
    "\n",
    "    # Select top-level links\n",
    "    for link in all_links:\n",
    "        if any(\n",
    "            k in link.lower()\n",
    "            for k in [\n",
    "                \"linkedin\",\n",
    "                \"github\",\n",
    "                \"portfolio\",\n",
    "                \"vercel\",\n",
    "                \"netlify\",\n",
    "                \"streamlit\",\n",
    "                \"huggingface\",\n",
    "                \"render\",\n",
    "                \"demo\",\n",
    "                \"live\",\n",
    "                \"project\",\n",
    "            ]\n",
    "        ):\n",
    "            top_links.append(link)\n",
    "\n",
    "    # Clean text\n",
    "    text = re.sub(r\"\\(cid:\\d+\\)\", \"\", full_text)  # remove PDF junk\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # collapse spaces & line breaks\n",
    "\n",
    "    # Prepend top-level links\n",
    "    if top_links:\n",
    "        text = \"Links: \" + \", \".join(sorted(set(top_links))) + \"\\n\\n\" + text\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "clean_cv_text = extract_clean_text(\"og_cv/afzal.pdf\")  # works for PDF, DOCX, TXT\n",
    "print(clean_cv_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a28615-8f8a-46b2-ac49-b2d62058d409",
   "metadata": {},
   "source": [
    "### When we used Docling for text extraction, it need time to detect file first,then it di extraction that also take few seconds. There is an issue in extracted text, docling cannot extract hyperlinks and also some portion of pdf becuase some pdf's are made up with latex template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed14528-36b9-4f77-812d-7ba0c54bcc13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "etl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
